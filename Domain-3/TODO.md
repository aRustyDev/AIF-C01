# Domain 3: Applications of Foundation Models

## Describe design considerations for applications that use foundation models.

**Objectives:**

- [ ] Identify selection criteria to choose pre-trained models #task
	- [ ] cost
	- [ ] modality
	- [ ] latency
	- [ ] multi-lingual
	- [ ] model size
	- [ ] model complexity
	- [ ] customization
	- [ ] input/output length
- [ ] Understand the effect of inference parameters on model responses #task
	- [ ] temperature
	- [ ] input/output length
- [ ] Define Retrieval Augmented Generation (RAG) and describe its business applications #task 
	- [ ] Amazon Bedrock
	- [ ] knowledge base
- [ ] Identify AWS services that help store embeddings within vector databases #task 
	- [ ] Amazon OpenSearch Service
	- [ ] Amazon Aurora
	- [ ] Amazon Neptune
	- [ ] Amazon DocumentDB [with MongoDB compatibility]
	- [ ] Amazon RDS for PostgreSQL
- [ ] Explain the cost tradeoffs of various approaches to foundation model customization #task 
	- [ ] pre-training
	- [ ] fine-tuning
	- [ ] in-context learning
	- [ ] RAG
- [ ] Understand the role of agents in multi-step tasks #task 
	- [ ] Agents for Amazon Bedrock

## Choose effective prompt engineering techniques.

**Objectives:**

- [ ] Describe the concepts and constructs of prompt engineering #task
	- [ ] context
	- [ ] instruction
	- [ ] negative prompts
	- [ ] model latent space
- [ ] Understand techniques for prompt engineering #task 
	- [ ] chain-of-thought
	- [ ] zero-shot
	- [ ] single-shot
	- [ ] few-shot
	- [ ] prompt templates
- [ ] Understand the benefits and best practices for prompt engineering #task
	- [ ] response quality improvement
	- [ ] experimentation
	- [ ] guardrails
	- [ ] discovery
	- [ ] specificity and concision
	- [ ] using multiple comments
- [ ] Define potential risks and limitations of prompt engineering #task
	- [ ] exposure
	- [ ] poisoning
	- [ ] hijacking
	- [ ] jailbreaking

## Describe the training and fine-tuning process for foundation models.

**Objectives:**

- [ ] Describe the key elements of training a foundation model #task
	- [ ] pre-training
	- [ ] fine-tuning
	- [ ] continuous pre-training
- [ ] Define methods for fine-tuning a foundation model #task 
	- [ ] instruction tuning
	- [ ] adapting models for specific domains
	- [ ] transfer learning
	- [ ] continuous pre-training
- [ ] Describe how to prepare data to fine-tune a foundation model #task
	- [ ] data curation
	- [ ] governance
	- [ ] size
	- [ ] labeling
	- [ ] representativeness
	- [ ] reinforcement learning from human feedback [RLHF]

## Describe methods to evaluate foundation model performance.

**Objectives:**

- [ ] Understand approaches to evaluate foundation model performance #task 
	- [ ] human evaluation
	- [ ] benchmark datasets
- [ ] Identify relevant metrics to assess foundation model performance #task 
	- [ ] Recall-Oriented Understudy for Gisting Evaluation [ROUGE]
	- [ ] Bilingual Evaluation Understudy [BLEU]
	- [ ] BERTScore
- [ ] Determine whether a foundation model effectively meets business objectives #task 
	- [ ] productivity
	- [ ] user engagement
	- [ ] task engineering

