# Domain 4: Guidelines for Responsible AI

## Explain the development of AI systems that are responsible.

**Objectives:**

- [ ] Identify features of responsible AI #task
	- [ ] bias, fairness, inclusivity, robustness, safety, veracity
- [ ] Understand how to use tools to identify features of responsible AI #task 
	- [ ] Guardrails for Amazon Bedrock
- [ ] Understand responsible practices to select a model #task
	- [ ] environmental considerations, sustainability
- [ ] Identify legal risks of working with generative AI #task 
	- [ ]  intellectual property infringement claims, biased model outputs, loss of customer trust, end user risk, hallucinations
- [ ] Identify characteristics of datasets #task
	- [ ] inclusivity, diversity, curated data sources, balanced datasets
- [ ] Understand effects of bias and variance #task
	- [ ] effects on demographic groups, inaccuracy, overfitting, underfitting
- [ ] Describe tools to detect and monitor bias, trustworthiness, and truthfulness #task
	- [ ] Analyzing label quality, human audits, subgroup analysis, Amazon SageMaker Clarify, SageMaker Model Monitor, Amazon Augmented AI [Amazon A2I]

## Recognize the importance of transparent and explainable models.

**Objectives:**

- [ ] Understand the differences between models that are transparent and #task
explainable and models that are not transparent and explainable.
- [ ] Understand the tools to identify transparent and explainable models (for #task
example, Amazon SageMaker Model Cards, open source models, data,
licensing).
- [ ] Identify tradeoffs between model safety and transparency (for example, #task
measure interpretability and performance).
- [ ] Understand principles of human-centered design for explainable AI #task

